Please run:
  python setup.py build_ext --inplace
(37360, 0, 6.435947288497596e-06)
load vocabulary
Parsing sentences from training set
enwik-200/BFGDiter_fromenwik9-sub0.001000SPPMI5_dim100_step2e-07_0.0
('Iter #:', 0, 'loss', 1130245298.7560046)
('Iter #:', 1, 'loss', 1123536360.96503)
('Iter #:', 2, 'loss', 1117326431.6431131)
('Iter #:', 3, 'loss', 1110529352.6965725)
('Iter #:', 4, 'loss', 1102205613.7933517)
('Iter #:', 5, 'loss', 1091758778.9097462)
('Iter #:', 6, 'loss', 1079326689.2081277)
('Iter #:', 7, 'loss', 1065909154.9773178)
('Iter #:', 8, 'loss', 1052773145.192675)
('Iter #:', 9, 'loss', 1040696124.1881796)
('Iter #:', 10, 'loss', 1029835900.9746925)
('Iter #:', 11, 'loss', 1020036270.1531199)
('Iter #:', 12, 'loss', 1011094165.6499563)
('Iter #:', 13, 'loss', 1002861313.800977)
('Iter #:', 14, 'loss', 995246302.2250865)
('Iter #:', 15, 'loss', 988187514.2603257)
('Iter #:', 16, 'loss', 981632849.1555605)
('Iter #:', 17, 'loss', 975533194.4432768)
('Iter #:', 18, 'loss', 969842692.731039)
('Iter #:', 19, 'loss', 964519833.1074272)
('Iter #:', 20, 'loss', 959527778.5208774)
('Iter #:', 21, 'loss', 954834060.5027589)
('Iter #:', 22, 'loss', 950410029.2750528)
('Iter #:', 23, 'loss', 946230341.4521029)
('Iter #:', 24, 'loss', 942272551.7108577)
('Iter #:', 25, 'loss', 938516758.2129672)
('Iter #:', 26, 'loss', 934945264.404148)
('Iter #:', 27, 'loss', 931542263.663746)
('Iter #:', 28, 'loss', 928293568.0361288)
('Iter #:', 29, 'loss', 925186391.3911539)
('Iter #:', 30, 'loss', 922209182.2732267)
('Iter #:', 31, 'loss', 919351493.7931108)
('Iter #:', 32, 'loss', 916603877.4630198)
('Iter #:', 33, 'loss', 913957791.1946791)
('Iter #:', 34, 'loss', 911405515.6525028)
('Iter #:', 35, 'loss', 908940076.2591484)
('Iter #:', 36, 'loss', 906555170.0373753)
('Iter #:', 37, 'loss', 904245097.3499475)
('Iter #:', 38, 'loss', 902004698.8349162)
('Iter #:', 39, 'loss', 899829297.754711)
('Iter #:', 40, 'loss', 897714647.796038)
--- 4364.120322227478 seconds ---
