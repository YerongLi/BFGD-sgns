Please run:
  python setup.py build_ext --inplace
(37360, 0, 6.435947288497596e-06)
load vocabulary
Parsing sentences from training set
enwik-200/BFGDiter_fromenwik9-sub0.001000SPPMI5_dim100_step1e-07_0.0
('Iter #:', 0, 'loss', 1130245298.7560046)
('Iter #:', 1, 'loss', 1126758841.9343832)
('Iter #:', 2, 'loss', 1123545271.9704897)
('Iter #:', 3, 'loss', 1120454555.3358507)
('Iter #:', 4, 'loss', 1117348909.4118307)
('Iter #:', 5, 'loss', 1114098710.983939)
('Iter #:', 6, 'loss', 1110582552.9939218)
('Iter #:', 7, 'loss', 1106691470.0211148)
('Iter #:', 8, 'loss', 1102337478.4724505)
('Iter #:', 9, 'loss', 1097465741.93002)
('Iter #:', 10, 'loss', 1092067686.6033661)
('Iter #:', 11, 'loss', 1086189877.3784435)
('Iter #:', 12, 'loss', 1079932514.1924262)
('Iter #:', 13, 'loss', 1073434494.6615566)
('Iter #:', 14, 'loss', 1066848589.7757819)
('Iter #:', 15, 'loss', 1060315583.6856723)
('Iter #:', 16, 'loss', 1053945911.4831744)
('Iter #:', 17, 'loss', 1047812417.0595204)
('Iter #:', 18, 'loss', 1041952683.7075981)
('Iter #:', 19, 'loss', 1036376844.0078261)
('Iter #:', 20, 'loss', 1031076891.1878127)
('Iter #:', 21, 'loss', 1026034932.3985217)
('Iter #:', 22, 'loss', 1021229310.828084)
('Iter #:', 23, 'loss', 1016638517.6718181)
('Iter #:', 24, 'loss', 1012243284.5894182)
('Iter #:', 25, 'loss', 1008027372.0193796)
('Iter #:', 26, 'loss', 1003977529.6261634)
('Iter #:', 27, 'loss', 1000083012.7260735)
('Iter #:', 28, 'loss', 996334938.9409261)
('Iter #:', 29, 'loss', 992725674.486873)
('Iter #:', 30, 'loss', 989248352.9399236)
('Iter #:', 31, 'loss', 985896557.5910542)
('Iter #:', 32, 'loss', 982664149.508226)
('Iter #:', 33, 'loss', 979545200.0629673)
('Iter #:', 34, 'loss', 976533984.2506558)
('Iter #:', 35, 'loss', 973625000.4967779)
('Iter #:', 36, 'loss', 970812995.2223945)
('Iter #:', 37, 'loss', 968092981.1819807)
('Iter #:', 38, 'loss', 965460245.8484973)
('Iter #:', 39, 'loss', 962910350.2313507)
('Iter #:', 40, 'loss', 960439120.3879957)
--- 4261.1942923069 seconds ---
