{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "\n",
    "from util.word2vec_as_MF import Word2vecMF\n",
    "from util.functions import *\n",
    "\n",
    "import time\n",
    "dimension = 100\n",
    "regularization =0.0\n",
    "model_enwik = Word2vecMF()\n",
    "negative = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess enwik9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\nskip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "skip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skip.get_latest_training_loss()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''skip.get_latest_training_loss()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ro_sgns model starting from SVD of SPPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "CPU times: user 2.27 s, sys: 44.4 ms, total: 2.32 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create word2vobject has no attributeec as matrix factorization model\n",
    "\n",
    "'''model_enwik.data_to_matrices(real_sentences, dimension, 5, \n",
    "                             DB_to_file='enwik-200/matrices.npz',\n",
    "                            indices_to_file='enwik-200/vocab.txt')'''\n",
    "#sentences = load('data/x1')\n",
    "\n",
    "model_enwik.data_to_matrices('data/x2', r=dimension, k=negative, \n",
    "                             DB_to_file=False,\n",
    "                            vocab_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_enwik.load_matrices('data/x1.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yerong/local/Anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05626258087294637\n",
      "218.6681790265787\n",
      "('Initial loss', 6259647.136484)\n",
      "93400\n"
     ]
    }
   ],
   "source": [
    "#C0, W0, step_size = BFGD_init(model_enwik, dimension=dimension, reg=regularization)\n",
    "C0, W0 = SPPMI_init(model_enwik, dimension=dimension, negative = negative)\n",
    "#C0, W0, step_size = RAND_init(model_enwik, dimension=dimension)\n",
    "print(np.count_nonzero(C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Train the model\\nstart_time = time.time()\\nopt_experiment(model_enwik,\\n               mode=\\'AM\\', \\n               d=dimension,\\n               eta = 5e-6,\\n               lbd = 1.0,\\n               MAX_ITER=189000,\\n               from_iter=0,\\n               start_from=\\'SVD\\',\\n               init=(True, C_svd, W_svd), display=True)\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(C0.shape[1])\n",
    "'''# Train the model\n",
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='AM', \n",
    "               d=dimension,\n",
    "               eta = 5e-6,\n",
    "               lbd = 1.0,\n",
    "               MAX_ITER=189000,\n",
    "               from_iter=0,\n",
    "               start_from='SVD',\n",
    "               init=(True, C_svd, W_svd), display=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwik-200/BFGDiter_fromtest_dim100_step1e-05_0.0\n",
      "('Iter #:', 0, 'loss', 6259647.136484)\n",
      "('Iter #:', 1, 'loss', 6243014.10426398)\n",
      "('Iter #:', 2, 'loss', 6231307.333076783)\n",
      "('Iter #:', 3, 'loss', 6207090.88606139)\n",
      "('Iter #:', 4, 'loss', 6141099.284061376)\n",
      "('Iter #:', 5, 'loss', 5997933.6603699075)\n",
      "('Iter #:', 6, 'loss', 5815760.463274696)\n",
      "('Iter #:', 7, 'loss', 5665073.119794607)\n",
      "('Iter #:', 8, 'loss', 5543744.169748818)\n",
      "('Iter #:', 9, 'loss', 5439249.8341753185)\n",
      "('Iter #:', 10, 'loss', 5347175.55540183)\n",
      "('Iter #:', 11, 'loss', 5265094.0506687695)\n",
      "('Iter #:', 12, 'loss', 5190628.541480141)\n",
      "('Iter #:', 13, 'loss', 5121638.3497929685)\n",
      "('Iter #:', 14, 'loss', 5056497.056384536)\n",
      "('Iter #:', 15, 'loss', 4994107.764759321)\n",
      "('Iter #:', 16, 'loss', 4933819.899752124)\n",
      "('Iter #:', 17, 'loss', 4875351.189228394)\n",
      "('Iter #:', 18, 'loss', 4818735.273569775)\n",
      "('Iter #:', 19, 'loss', 4764265.287300496)\n",
      "('Iter #:', 20, 'loss', 4712394.958796121)\n",
      "('Iter #:', 21, 'loss', 4663587.782789797)\n",
      "('Iter #:', 22, 'loss', 4618160.153178451)\n",
      "('Iter #:', 23, 'loss', 4576190.839869479)\n",
      "('Iter #:', 24, 'loss', 4537527.282802494)\n",
      "('Iter #:', 25, 'loss', 4501876.746783038)\n",
      "('Iter #:', 26, 'loss', 4468960.960151785)\n",
      "('Iter #:', 27, 'loss', 4439459.384584379)\n",
      "('Iter #:', 28, 'loss', 4425280.933327931)\n",
      "('Iter #:', 29, 'loss', 4543277.142144454)\n",
      "('Iter #:', 30, 'loss', 4928720.207587595)\n",
      "('Iter #:', 31, 'loss', 5679024.171620935)\n",
      "('Iter #:', 32, 'loss', 4574377.23443593)\n",
      "('Iter #:', 33, 'loss', 5455711.287641331)\n",
      "('Iter #:', 34, 'loss', 4947774.892399066)\n",
      "('Iter #:', 35, 'loss', 6544292.561472132)\n",
      "('Iter #:', 36, 'loss', 4544427.500231933)\n",
      "('Iter #:', 37, 'loss', 5799044.404089378)\n",
      "('Iter #:', 38, 'loss', 5303845.727407484)\n",
      "('Iter #:', 39, 'loss', 6483753.035476779)\n",
      "('Iter #:', 40, 'loss', 6464957.5694582155)\n",
      "('Iter #:', 41, 'loss', 8535270.539100919)\n",
      "('Iter #:', 42, 'loss', 6069844.352512784)\n",
      "('Iter #:', 43, 'loss', 10569744.526548628)\n",
      "('Iter #:', 44, 'loss', 10211130.030478675)\n",
      "('Iter #:', 45, 'loss', 17344302.220788557)\n",
      "('Iter #:', 46, 'loss', 16689501.150722122)\n",
      "('Iter #:', 47, 'loss', 20118309.95027214)\n",
      "('Iter #:', 48, 'loss', 22753497.506861225)\n",
      "('Iter #:', 49, 'loss', 34747777.22581766)\n",
      "('Iter #:', 50, 'loss', 31471738.96812073)\n",
      "--- 13.051996946334839 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='BFGD',\n",
    "               d=dimension,\n",
    "               eta=1e-5,\n",
    "               #eta = step_size,\n",
    "               reg = regularization,\n",
    "               MAX_ITER=50,\n",
    "               from_iter=0,\n",
    "               start_from='test',\n",
    "               itv_print=1,\n",
    "               itv_save=1,\n",
    "               init=(True, C0, W0), display=True,\n",
    "               autostop=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
