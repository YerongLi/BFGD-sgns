{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run:\n",
      "  python setup.py build_ext --inplace\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "\n",
    "from util.word2vec_as_MF import Word2vecMF\n",
    "from util.functions import *\n",
    "\n",
    "import time\n",
    "dimension = 100\n",
    "regularization =0.0\n",
    "model_enwik = Word2vecMF()\n",
    "negative = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess enwik9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\nskip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "skip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skip.get_latest_training_loss()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''skip.get_latest_training_loss()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ro_sgns model starting from SVD of SPPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "Length of vocabulary is: 356\n",
      "CPU times: user 578 ms, sys: 7.87 ms, total: 585 ms\n",
      "Wall time: 582 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create word2vobject has no attributeec as matrix factorization model\n",
    "\n",
    "'''model_enwik.data_to_matrices(real_sentences, dimension, 5, \n",
    "                             DB_to_file='enwik-2            try:\n",
    "00/matrices.npz',\n",
    "                            indices_to_file='enwik-200/vocab.txt')'''\n",
    "#sentences = load('data/x1')\n",
    "#model_enwik.load_vocab('v1.txt')\n",
    "model_enwik.data_to_matrices('data/x1', r=dimension, k=negative,\n",
    "                             DB_to_file=False,\n",
    "                            vocab_to_file='v1.txt')\n",
    "#model_enwik.save_vocabulary(from_file='data/x1',vocab_to_file='v.txt', r=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047784370660270165\n",
      "62.27460890120043\n",
      "('reg ', 1.0575829573654522e-13)\n",
      "('Initial loss', 1808805.0213349368)\n",
      "35600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yerong/local/Anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#C0, W0, step_size = BFGD_init(model_enwik, dimension=dimension, reg=regularization)\n",
    "C0, W0 = SPPMI_init(model_enwik, dimension=dimension, negative = negative)\n",
    "#C0, W0, step_size = RAND_init(model_enwik, dimension=dimension)\n",
    "model_enwik.save_CW('initializations/NYT',0)\n",
    "print(np.count_nonzero(C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Train the model\\nstart_time = time.time()\\nopt_experiment(model_enwik,\\n               mode=\\'AM\\', \\n               d=dimension,\\n               eta = 5e-6,\\n               lbd = 1.0,\\n               MAX_ITER=189000,\\n               from_iter=0,\\n               start_from=\\'SVD\\',\\n               init=(True, C_svd, W_svd), display=True)\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(C0.shape[1])\n",
    "'''# Train the model\n",
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='AM', \n",
    "               d=dimension,\n",
    "               eta = 5e-6,\n",
    "               lbd = 1.0,\n",
    "               MAX_ITER=189000,\n",
    "               from_iter=0,\n",
    "               start_from='SVD',\n",
    "               init=(True, C_svd, W_svd), display=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwik-200/BFGDiter_fromtest_dim100_step1e-05_0.0\n",
      "('reg ', 1.0575829573654522e-13)\n",
      "('Iter #:', 0, 'loss', 1808805.0213349368)\n",
      "('reg ', 0.015319033869243501)\n",
      "('Iter #:', 1, 'loss', 1807098.5038878059)\n",
      "('reg ', 0.025543132619958855)\n",
      "('Iter #:', 2, 'loss', 1805833.1888186142)\n",
      "('reg ', 0.03280857371592869)\n",
      "('Iter #:', 3, 'loss', 1804774.8047999986)\n",
      "('reg ', 0.03888353358583777)\n",
      "('Iter #:', 4, 'loss', 1803731.2341214044)\n",
      "('reg ', 0.04568187901735637)\n",
      "('Iter #:', 5, 'loss', 1802516.6522106032)\n",
      "('reg ', 0.05574735316134854)\n",
      "('Iter #:', 6, 'loss', 1800919.5783693437)\n",
      "('reg ', 0.0725169358502605)\n",
      "('Iter #:', 7, 'loss', 1798671.0158157595)\n",
      "('reg ', 0.1002695394697543)\n",
      "('Iter #:', 8, 'loss', 1795412.8785928302)\n",
      "('reg ', 0.1440951869136372)\n",
      "('Iter #:', 9, 'loss', 1790674.0421115258)\n",
      "('reg ', 0.20999008835071908)\n",
      "('Iter #:', 10, 'loss', 1783874.3028980736)\n",
      "('reg ', 0.3044683969766074)\n",
      "('Iter #:', 11, 'loss', 1774393.5644365659)\n",
      "('reg ', 0.4329830545841495)\n",
      "('Iter #:', 12, 'loss', 1761746.1112003534)\n",
      "('reg ', 0.5971226698698476)\n",
      "('Iter #:', 13, 'loss', 1745842.2233343634)\n",
      "('reg ', 0.7920591919484451)\n",
      "('Iter #:', 14, 'loss', 1727183.352066779)\n",
      "('reg ', 1.006868388702858)\n",
      "('Iter #:', 15, 'loss', 1706777.0820953352)\n",
      "('reg ', 1.2283044247142685)\n",
      "('Iter #:', 16, 'loss', 1685783.0672154678)\n",
      "('reg ', 1.4450375548548025)\n",
      "('Iter #:', 17, 'loss', 1665163.5164558804)\n",
      "('reg ', 1.6497225909670938)\n",
      "('Iter #:', 18, 'loss', 1645527.616505873)\n",
      "('reg ', 1.838949282591382)\n",
      "('Iter #:', 19, 'loss', 1627148.3928161217)\n",
      "('reg ', 2.0121570384123295)\n",
      "('Iter #:', 20, 'loss', 1610060.9206691475)\n",
      "('reg ', 2.170392176408898)\n",
      "('Iter #:', 21, 'loss', 1594169.5180275277)\n",
      "('reg ', 2.3153562315380576)\n",
      "('Iter #:', 22, 'loss', 1579328.104633487)\n",
      "('reg ', 2.4488364970074894)\n",
      "('Iter #:', 23, 'loss', 1565387.6363044071)\n",
      "('reg ', 2.5724346760115133)\n",
      "('Iter #:', 24, 'loss', 1552218.3697129395)\n",
      "('reg ', 2.687478078290346)\n",
      "('Iter #:', 25, 'loss', 1539716.8003525024)\n",
      "('reg ', 2.7950247267259405)\n",
      "('Iter #:', 26, 'loss', 1527804.663149895)\n",
      "('reg ', 2.8959079168873956)\n",
      "('Iter #:', 27, 'loss', 1516424.483926665)\n",
      "('reg ', 2.990790812697019)\n",
      "('Iter #:', 28, 'loss', 1505534.0968400645)\n",
      "('reg ', 3.080216678454643)\n",
      "('Iter #:', 29, 'loss', 1495101.3457101583)\n",
      "('reg ', 3.164648532830888)\n",
      "('Iter #:', 30, 'loss', 1485099.5832420134)\n",
      "('reg ', 3.2444964723159635)\n",
      "('Iter #:', 31, 'loss', 1475504.2835253961)\n",
      "('reg ', 3.3201336209391834)\n",
      "('Iter #:', 32, 'loss', 1466290.887028874)\n",
      "('reg ', 3.3919034251527935)\n",
      "('Iter #:', 33, 'loss', 1457433.8085703484)\n",
      "('reg ', 3.4601218469082933)\n",
      "('Iter #:', 34, 'loss', 1448906.3618046977)\n",
      "('reg ', 3.525077752730079)\n",
      "('Iter #:', 35, 'loss', 1440681.2465239966)\n",
      "('reg ', 3.587033642010857)\n",
      "('Iter #:', 36, 'loss', 1432731.2500325483)\n",
      "('reg ', 3.646227431929085)\n",
      "('Iter #:', 37, 'loss', 1425029.9139610373)\n",
      "('reg ', 3.702874994586893)\n",
      "('Iter #:', 38, 'loss', 1417552.0501391632)\n",
      "('reg ', 3.757172806363737)\n",
      "('Iter #:', 39, 'loss', 1410274.0934647324)\n",
      "('reg ', 3.8093002428490723)\n",
      "('Iter #:', 40, 'loss', 1403174.3322730905)\n",
      "('reg ', 3.859421377034987)\n",
      "('Iter #:', 41, 'loss', 1396233.0667750286)\n",
      "('reg ', 3.9076863632484957)\n",
      "('Iter #:', 42, 'loss', 1389432.7343693946)\n",
      "('reg ', 3.954232555602163)\n",
      "('Iter #:', 43, 'loss', 1382758.0230457918)\n",
      "('reg ', 3.9991854744417976)\n",
      "('Iter #:', 44, 'loss', 1376195.9782171757)\n",
      "('reg ', 4.042659671913558)\n",
      "('Iter #:', 45, 'loss', 1369736.096163392)\n",
      "('reg ', 4.084759502430734)\n",
      "('Iter #:', 46, 'loss', 1363370.3887942)\n",
      "('reg ', 4.125579786906068)\n",
      "('Iter #:', 47, 'loss', 1357093.3995086032)\n",
      "('reg ', 4.165206364838928)\n",
      "('Iter #:', 48, 'loss', 1350902.1488034157)\n",
      "('reg ', 4.203716544768605)\n",
      "('Iter #:', 49, 'loss', 1344795.9914448555)\n",
      "('reg ', 4.241179481886712)\n",
      "('Iter #:', 50, 'loss', 1338776.3746644221)\n",
      "--- 1.8278214931488037 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='BFGD',\n",
    "               d=dimension,\n",
    "               eta=1e-5,\n",
    "               #eta = step_size,\n",
    "               reg = regularization,\n",
    "               MAX_ITER=50,\n",
    "               from_iter=0,\n",
    "               start_from='test',\n",
    "               itv_print=1,\n",
    "               itv_save=1,\n",
    "               init=(True, C0, W0), display=True,\n",
    "               autostop=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
