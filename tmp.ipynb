{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run:\n",
      "  python setup.py build_ext --inplace\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "\n",
    "from util.word2vec_as_MF import Word2vecMF\n",
    "from util.functions import *\n",
    "\n",
    "import time\n",
    "dimension = 100\n",
    "regularization =0.0\n",
    "model_enwik = Word2vecMF()\n",
    "negative = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess enwik9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\nskip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "skip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skip.get_latest_training_loss()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''skip.get_latest_training_loss()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ro_sgns model starting from SVD of SPPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356, 0, 0.0002996246049420774)\n",
      "Parsing sentences from training set\n",
      "CPU times: user 766 ms, sys: 4.71 ms, total: 770 ms\n",
      "Wall time: 765 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create word2vobject has no attributeec as matrix factorization model\n",
    "\n",
    "'''model_enwik.data_to_matrices(real_sentences, dimension, 5, \n",
    "                             DB_to_file='enwik-200/matrices.npz',\n",
    "                            indices_to_file='enwik-200/vocab.txt')'''\n",
    "#sentences = load('data/x1')\n",
    "model_enwik.load_vocab('v1.txt')\n",
    "model_enwik.data_to_matrices('data/x1', r=dimension, k=negative,\n",
    "                             DB_to_file=False,\n",
    "                            vocab_to_file='v1.txt')\n",
    "#model_enwik.save_vocabulary(from_file='data/x1',vocab_to_file='v.txt', r=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047784370660270165\n",
      "62.27460890120043\n",
      "('Initial loss', 1808805.021334937)\n",
      "35600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yerong/local/Anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#C0, W0, step_size = BFGD_init(model_enwik, dimension=dimension, reg=regularization)\n",
    "C0, W0 = SPPMI_init(model_enwik, dimension=dimension, negative = negative)\n",
    "#C0, W0, step_size = RAND_init(model_enwik, dimension=dimension)\n",
    "print(np.count_nonzero(C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Train the model\\nstart_time = time.time()\\nopt_experiment(model_enwik,\\n               mode=\\'AM\\', \\n               d=dimension,\\n               eta = 5e-6,\\n               lbd = 1.0,\\n               MAX_ITER=189000,\\n               from_iter=0,\\n               start_from=\\'SVD\\',\\n               init=(True, C_svd, W_svd), display=True)\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(C0.shape[1])\n",
    "'''# Train the model\n",
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='AM', \n",
    "               d=dimension,\n",
    "               eta = 5e-6,\n",
    "               lbd = 1.0,\n",
    "               MAX_ITER=189000,\n",
    "               from_iter=0,\n",
    "               start_from='SVD',\n",
    "               init=(True, C_svd, W_svd), display=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwik-200/BFGDiter_fromtest_dim100_step1e-05_0.0\n",
      "('Iter #:', 0, 'loss', 1808805.021334937)\n",
      "('Iter #:', 1, 'loss', 1807098.5038878059)\n",
      "('Iter #:', 2, 'loss', 1805833.1888186142)\n",
      "('Iter #:', 3, 'loss', 1804774.8047999989)\n",
      "('Iter #:', 4, 'loss', 1803731.2341214041)\n",
      "('Iter #:', 5, 'loss', 1802516.6522106035)\n",
      "('Iter #:', 6, 'loss', 1800919.578369344)\n",
      "('Iter #:', 7, 'loss', 1798671.0158157605)\n",
      "('Iter #:', 8, 'loss', 1795412.87859283)\n",
      "('Iter #:', 9, 'loss', 1790674.042111526)\n",
      "('Iter #:', 10, 'loss', 1783874.3028980738)\n",
      "('Iter #:', 11, 'loss', 1774393.5644365656)\n",
      "('Iter #:', 12, 'loss', 1761746.1112003534)\n",
      "('Iter #:', 13, 'loss', 1745842.2233343634)\n",
      "('Iter #:', 14, 'loss', 1727183.3520667793)\n",
      "('Iter #:', 15, 'loss', 1706777.0820953352)\n",
      "('Iter #:', 16, 'loss', 1685783.0672154678)\n",
      "('Iter #:', 17, 'loss', 1665163.5164558804)\n",
      "('Iter #:', 18, 'loss', 1645527.6165058727)\n",
      "('Iter #:', 19, 'loss', 1627148.392816122)\n",
      "('Iter #:', 20, 'loss', 1610060.9206691475)\n",
      "('Iter #:', 21, 'loss', 1594169.5180275275)\n",
      "('Iter #:', 22, 'loss', 1579328.1046334873)\n",
      "('Iter #:', 23, 'loss', 1565387.636304407)\n",
      "('Iter #:', 24, 'loss', 1552218.3697129395)\n",
      "('Iter #:', 25, 'loss', 1539716.8003525021)\n",
      "('Iter #:', 26, 'loss', 1527804.6631498942)\n",
      "('Iter #:', 27, 'loss', 1516424.483926665)\n",
      "('Iter #:', 28, 'loss', 1505534.0968400643)\n",
      "('Iter #:', 29, 'loss', 1495101.345710158)\n",
      "('Iter #:', 30, 'loss', 1485099.5832420136)\n",
      "('Iter #:', 31, 'loss', 1475504.2835253966)\n",
      "('Iter #:', 32, 'loss', 1466290.8870288744)\n",
      "('Iter #:', 33, 'loss', 1457433.8085703487)\n",
      "('Iter #:', 34, 'loss', 1448906.3618046977)\n",
      "('Iter #:', 35, 'loss', 1440681.2465239963)\n",
      "('Iter #:', 36, 'loss', 1432731.2500325483)\n",
      "('Iter #:', 37, 'loss', 1425029.9139610375)\n",
      "('Iter #:', 38, 'loss', 1417552.050139163)\n",
      "('Iter #:', 39, 'loss', 1410274.0934647326)\n",
      "('Iter #:', 40, 'loss', 1403174.3322730905)\n",
      "('Iter #:', 41, 'loss', 1396233.0667750286)\n",
      "('Iter #:', 42, 'loss', 1389432.7343693941)\n",
      "('Iter #:', 43, 'loss', 1382758.0230457918)\n",
      "('Iter #:', 44, 'loss', 1376195.978217176)\n",
      "('Iter #:', 45, 'loss', 1369736.0961633925)\n",
      "('Iter #:', 46, 'loss', 1363370.3887942003)\n",
      "('Iter #:', 47, 'loss', 1357093.3995086032)\n",
      "('Iter #:', 48, 'loss', 1350902.1488034162)\n",
      "('Iter #:', 49, 'loss', 1344795.991444856)\n",
      "('Iter #:', 50, 'loss', 1338776.3746644221)\n",
      "--- 1.8434805870056152 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='BFGD',\n",
    "               d=dimension,\n",
    "               eta=1e-5,\n",
    "               #eta = step_size,\n",
    "               reg = regularization,\n",
    "               MAX_ITER=50,\n",
    "               from_iter=0,\n",
    "               start_from='test',\n",
    "               itv_print=1,\n",
    "               itv_save=1,\n",
    "               init=(True, C0, W0), display=True,\n",
    "               autostop=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
