{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run:\n",
      "  python setup.py build_ext --inplace\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "\n",
    "from util.word2vec_as_MF import Word2vecMF\n",
    "from util.functions import *\n",
    "\n",
    "import time\n",
    "dimension = 100\n",
    "regularization =0.0\n",
    "model_enwik = Word2vecMF()\n",
    "negative = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess enwik9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\nskip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "skip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skip.get_latest_training_loss()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''skip.get_latest_training_loss()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ro_sgns model starting from SVD of SPPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "CPU times: user 615 ms, sys: 26.3 ms, total: 641 ms\n",
      "Wall time: 638 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create word2vobject has no attributeec as matrix factorization model\n",
    "\n",
    "'''model_enwik.data_to_matrices(real_sentences, dimension, 5, \n",
    "                             DB_to_file='enwik-2            try:\n",
    "00/matrices.npz',\n",
    "                            indices_to_file='enwik-200/vocab.txt')'''\n",
    "#sentences = load('data/x1')\n",
    "#model_enwik.load_vocab('v1.txt')\n",
    "model_enwik.data_to_matrices('data/x1', r=dimension, k=negative,\n",
    "                             DB_to_file=False,\n",
    "                            vocab_to_file='v1.txt')\n",
    "#model_enwik.save_vocabulary(from_file='data/x1',vocab_to_file='v.txt', r=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047784370660270165\n",
      "62.27460890120043\n",
      "('Initial loss', 1808805.021334937)\n",
      "35600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yerong/local/Anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#C0, W0, step_size = BFGD_init(model_enwik, dimension=dimension, reg=regularization)\n",
    "C0, W0 = SPPMI_init(model_enwik, dimension=dimension, negative = negative)\n",
    "#C0, W0, step_size = RAND_init(model_enwik, dimension=dimension)\n",
    "print(np.count_nonzero(C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Train the model\\nstart_time = time.time()\\nopt_experiment(model_enwik,\\n               mode=\\'AM\\', \\n               d=dimension,\\n               eta = 5e-6,\\n               lbd = 1.0,\\n               MAX_ITER=189000,\\n               from_iter=0,\\n               start_from=\\'SVD\\',\\n               init=(True, C_svd, W_svd), display=True)\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(C0.shape[1])\n",
    "'''# Train the model\n",
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='AM', \n",
    "               d=dimension,\n",
    "               eta = 5e-6,\n",
    "               lbd = 1.0,\n",
    "               MAX_ITER=189000,\n",
    "               from_iter=0,\n",
    "               start_from='SVD',\n",
    "               init=(True, C_svd, W_svd), display=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwik-200/PSiter_fromtest_dim100_step1e-05_0.0\n",
      "('Iter #:', 0, 'loss', 1808805.021334937)\n",
      "('Iter #:', 1, 'loss', 1808568.2662150215)\n",
      "('Iter #:', 2, 'loss', 1808339.1622854602)\n",
      "('Iter #:', 3, 'loss', 1808116.5966503131)\n",
      "('Iter #:', 4, 'loss', 1807899.4707686696)\n",
      "('Iter #:', 5, 'loss', 1807686.6919807866)\n",
      "('Iter #:', 6, 'loss', 1807477.164980221)\n",
      "('Iter #:', 7, 'loss', 1807269.7831876983)\n",
      "('Iter #:', 8, 'loss', 1807063.419986541)\n",
      "('Iter #:', 9, 'loss', 1806856.9197850171)\n",
      "('Iter #:', 10, 'loss', 1806649.0888782912)\n",
      "('Iter #:', 11, 'loss', 1806438.686092231)\n",
      "('Iter #:', 12, 'loss', 1806224.4132035715)\n",
      "('Iter #:', 13, 'loss', 1806004.9051464677)\n",
      "('Iter #:', 14, 'loss', 1805778.7200348962)\n",
      "('Iter #:', 15, 'loss', 1805544.3290543377)\n",
      "('Iter #:', 16, 'loss', 1805300.1063054805)\n",
      "('Iter #:', 17, 'loss', 1805044.3187179104)\n",
      "('Iter #:', 18, 'loss', 1804775.1161936866)\n",
      "('Iter #:', 19, 'loss', 1804490.5221896716)\n",
      "('Iter #:', 20, 'loss', 1804188.4250039053)\n",
      "('Iter #:', 21, 'loss', 1803866.5700948178)\n",
      "('Iter #:', 22, 'loss', 1803522.553832083)\n",
      "('Iter #:', 23, 'loss', 1803153.8191527117)\n",
      "('Iter #:', 24, 'loss', 1802757.6536728926)\n",
      "('Iter #:', 25, 'loss', 1802331.1908812206)\n",
      "('Iter #:', 26, 'loss', 1801871.4151064092)\n",
      "('Iter #:', 27, 'loss', 1801375.1710050632)\n",
      "('Iter #:', 28, 'loss', 1800839.178342994)\n",
      "('Iter #:', 29, 'loss', 1800260.0528356412)\n",
      "('Iter #:', 30, 'loss', 1799634.3337566862)\n",
      "('Iter #:', 31, 'loss', 1798958.5189055302)\n",
      "('Iter #:', 32, 'loss', 1798229.1073314615)\n",
      "('Iter #:', 33, 'loss', 1797442.6499348884)\n",
      "('Iter #:', 34, 'loss', 1796595.8076992745)\n",
      "('Iter #:', 35, 'loss', 1795685.4168540114)\n",
      "('Iter #:', 36, 'loss', 1794708.5597420463)\n",
      "('Iter #:', 37, 'loss', 1793662.639592869)\n",
      "('Iter #:', 38, 'loss', 1792545.45682175)\n",
      "('Iter #:', 39, 'loss', 1791355.283943116)\n",
      "('Iter #:', 40, 'loss', 1790090.9357625989)\n",
      "('Iter #:', 41, 'loss', 1788751.8312645266)\n",
      "('Iter #:', 42, 'loss', 1787338.043599922)\n",
      "('Iter #:', 43, 'loss', 1785850.334848536)\n",
      "('Iter #:', 44, 'loss', 1784290.1727946906)\n",
      "('Iter #:', 45, 'loss', 1782659.7278039686)\n",
      "('Iter #:', 46, 'loss', 1780961.8489616422)\n",
      "('Iter #:', 47, 'loss', 1779200.0198452466)\n",
      "('Iter #:', 48, 'loss', 1777378.2955391286)\n",
      "('Iter #:', 49, 'loss', 1775501.2236349306)\n",
      "('Iter #:', 50, 'loss', 1773573.752884016)\n",
      "--- 3.2322146892547607 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='PS',\n",
    "               d=dimension,\n",
    "               eta=1e-5,\n",
    "               #eta = step_size,\n",
    "               reg = regularization,\n",
    "               MAX_ITER=50,\n",
    "               from_iter=0,\n",
    "               start_from='test',\n",
    "               itv_print=1,\n",
    "               itv_save=1,\n",
    "               init=(True, C0, W0), display=True,\n",
    "               autostop=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
