{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "\n",
    "from util.word2vec_as_MF import Word2vecMF\n",
    "from util.functions import *\n",
    "\n",
    "import time\n",
    "dimension = 100\n",
    "regularization =0.0\n",
    "model_enwik = Word2vecMF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess enwik9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\nskip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "skip = Word2Vec(real_sentences, size = dimension, compute_loss=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skip.get_latest_training_loss()'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''skip.get_latest_training_loss()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ro_sgns model starting from SVD of SPPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "CPU times: user 8.86 s, sys: 236 ms, total: 9.1 s\n",
      "Wall time: 9.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create word2vobject has no attributeec as matrix factorization model\n",
    "\n",
    "'''model_enwik.data_to_matrices(real_sentences, dimension, 5, \n",
    "                             DB_to_file='enwik-200/matrices.npz',\n",
    "                            indices_to_file='enwik-200/vocab.txt')'''\n",
    "#sentences = load('data/x1')\n",
    "\n",
    "model_enwik.data_to_matrices('data/x4', r=dimension, k=5, \n",
    "                             DB_to_file=False,\n",
    "                            vocab_to_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_enwik.load_matrices('data/x1.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yerong/local/Anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04052945679513818\n",
      "813.1464918741565\n",
      "(array([4.14720727, 2.22970812, 0.        , ..., 0.        , 0.        ,\n",
      "       0.        ]), 'SPPMI')\n",
      "(array([2.07944154, 0.        , 2.56494936, ...,       -inf,       -inf,\n",
      "             -inf]), 'logD')\n",
      "(array([-2.06776573, -2.22970812,  2.99282618, ..., -2.5106884 ,\n",
      "       -2.42654372, -2.16823626]), 'logB')\n",
      "('Initial loss', 27381368.617120914, 'theoretical step size', 1.175046174557565e-09)\n",
      "303600\n"
     ]
    }
   ],
   "source": [
    "#C0, W0, step_size = BFGD_init(model_enwik, dimension=dimension, reg=regularization)\n",
    "C0, W0, step_size = SPPMI_init(model_enwik, dimension=dimension)\n",
    "print(np.count_nonzero(C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Train the model\\nstart_time = time.time()\\nopt_experiment(model_enwik,\\n               mode=\\'AM\\', \\n               d=dimension,\\n               eta = 5e-6,\\n               lbd = 1.0,\\n               MAX_ITER=189000,\\n               from_iter=0,\\n               start_from=\\'SVD\\',\\n               init=(True, C_svd, W_svd), display=True)\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(C0.shape[1])\n",
    "'''# Train the model\n",
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='AM', \n",
    "               d=dimension,\n",
    "               eta = 5e-6,\n",
    "               lbd = 1.0,\n",
    "               MAX_ITER=189000,\n",
    "               from_iter=0,\n",
    "               start_from='SVD',\n",
    "               init=(True, C_svd, W_svd), display=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwik-200/PSiter_fromtest_dim100_step1e-05_0.0\n",
      "('Iter #:', 0, 'loss', 27381368.617120914)\n",
      "('Iter #:', 1, 'loss', 27381368.617120914)\n",
      "('Iter #:', 2, 'loss', 27376208.928626776)\n",
      "('Iter #:', 3, 'loss', 27371114.124780748)\n",
      "('Iter #:', 4, 'loss', 27366055.41602728)\n",
      "('Iter #:', 5, 'loss', 27361003.099034976)\n",
      "--- 27.689342498779297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "opt_experiment(model_enwik,\n",
    "               mode='PS',\n",
    "               d=dimension,\n",
    "               eta=1e-5,\n",
    "               #eta = step_size,\n",
    "               reg = regularization,\n",
    "               MAX_ITER=5,\n",
    "               from_iter=0,\n",
    "               start_from='test',\n",
    "               itv_print=1,\n",
    "               itv_save=100000,\n",
    "               init=(True, C0, W0), display=True,\n",
    "               autostop=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
