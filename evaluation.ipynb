{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "\n",
    "from util.word2vec_as_MF import Word2vecMF\n",
    "from util.functions import *\n",
    "from util.visualize import *\n",
    "\n",
    "import time\n",
    "dimension = 20\n",
    "model =  Word2vecMF()\n",
    "dictionary = {'Evaluation':[],'BFGD':[],'RO':[], 'word2vec':[], 'number of pairs':[]}\n",
    "model.load_matrices(from_file='enwik-200/enwik8.npz');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "sentences=load(from_file='data/enwik8.txt')\n",
    "skip = Word2Vec(sentences, size=dimension, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/men3000.csv\n",
      "0.5554766446712811 1301\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/men3000.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "'''score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=934);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))'''\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "'''dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)'''\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'datasets/verb143.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/wordsim353.csv\n",
      "0.4967901223313615 253\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/wordsim353.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "'''score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))'''\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "#dictionary['BFGD'].append(score1)\n",
    "#dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'datasets/MTURK-771.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=',');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'datasets/mturk287.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'datasets/rw2034.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "'''score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))'''\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "'''dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)'''\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'datasets/simlex999.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dictionary)\n",
    "cols = df.columns.tolist()\n",
    "j = cols.index('Evaluation')\n",
    "cols[0],cols[j]=cols[j], cols[0]\n",
    "j = cols.index('number of pairs')\n",
    "cols[-1],cols[j]=cols[j], cols[-1]\n",
    "df=df[cols]\n",
    "df.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enwik8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'datasets/verb143.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/men3000.csv\n",
      "0.0355913346481999 1301\n"
     ]
    }
   ],
   "source": [
    "from util.visualize import *\n",
    "\n",
    "#Path = 'datasets/simlex999.csv'\n",
    "Path = 'datasets/men3000.csv'\n",
    "#Path = 'datasets/rw2034.csv'\n",
    "#Path = 'datasets/wordsim353.csv'\n",
    "#Path = 'datasets/MTURK-771.csv'\n",
    "#datapath='enwik-200/BFGDiter_fromenwik8_dim100_step1e-07_0.0'\n",
    "datapath='enwik-200/BFGDiter_fromenwik8_dim100_step1.49198074496e-08_0.0'\n",
    "datapath='enwik-200/BFGDiter_fromenwik8_dense_dim100_step1e-07_0.0'\n",
    "datapath='enwik-200/PSiter_fromenwik8_dim100_step1e-05_0.0'\n",
    "print(Path)\n",
    "\n",
    "\n",
    "score1, _, _, chosen_pairs = correlation(model = model, \n",
    "                                         benchmark = Path, \n",
    "                                         from_folder=datapath,\n",
    "                                         index=200)\n",
    "print(score1, len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "#datapath='enwik-200/BFGDiter_fromenwik8_dense_dim100_step1e-07_0.0'\n",
    "#datapath='enwik-200/PSiter_fromenwik8_dim100_step1e-05_0.0'\n",
    "#datapath='enwik-200/PSiter_fromenwik8PMM_dim100_step1e-05_0.0'\n",
    "datapath='enwik-200/PSiter_from9PMM_dim100_step5e-05_0.0'\n",
    "datasets_corr(model = model, from_folder=datapath, MAX_ITER=500000,plot_corrs=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import  svd\n",
    "X = np.random.normal(size=[20,18])\n",
    "P, D, Q = np.linalg.svd(X, full_matrices=False)\n",
    "X_a = P @ np.diag(D) @ Q\n",
    "print(np.std(X), np.std(X_a), np.std(X - X_a))\n",
    "print('Is X close to X_a?', np.isclose(X, X_a).all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
