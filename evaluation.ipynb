{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec, Word2Vec\n",
    "import logging\n",
    "\n",
    "from word2vec_as_MF import Word2vecMF\n",
    "from functions import *\n",
    "\n",
    "import time\n",
    "dimension = 20\n",
    "model =  Word2vecMF()\n",
    "dictionary = {'Evaluation':[],'BFGD':[],'RO':[], 'word2vec':[], 'number of pairs':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "sentences=parse(from_file='data/x2')\n",
    "skip = Word2Vec(sentences, size=dimension, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/men3000.csv\n",
      "[0.20834729] 60\n",
      "[0.05638974] 60\n",
      "-0.14442223771888119 60\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/men3000.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           ITER=[190000]);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           ITER=[360000]);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1[0])\n",
    "dictionary['RO'].append(score2[0])\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/verb143.csv\n",
      "[0.0227791] 11\n",
      "[-0.21412356] 11\n",
      "-0.1138955118945513 11\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/verb143.csv'\n",
    "print(Path)\n",
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           ITER=[190000]);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           ITER=[360000]);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1[0])\n",
    "dictionary['RO'].append(score2[0])\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/wordsim353.csv\n",
      "[0.25295573] 32\n",
      "[-0.17102007] 32\n",
      "0.3609201738190157 32\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/wordsim353.csv'\n",
    "print(Path)\n",
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           ITER=[190000]);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           ITER=[360000]);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1[0])\n",
    "dictionary['RO'].append(score2[0])\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/MTURK-771.csv\n",
      "[0.40262635] 30\n",
      "[0.32472739] 30\n",
      "0.4751836660409047 30\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/MTURK-771.csv'\n",
    "print(Path)\n",
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "df = pd.read_csv(Path,header=None, delimiter=',');\n",
    "score1, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           ITER=[190000]);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           ITER=[360000]);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1[0])\n",
    "dictionary['RO'].append(score2[0])\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/mturk287.csv\n",
      "[0.36969697] 10\n",
      "0.6969696969696969 10\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/mturk287.csv'\n",
    "print(Path)\n",
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           ITER=[190000]);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           ITER=[360000]);\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1[0])\n",
    "dictionary['RO'].append(score2[0])\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/rw2034.csv\n",
      "[1.] 3\n",
      "[0.5] 3\n",
      "0.5 3\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/rw2034.csv'\n",
    "print(Path)\n",
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           ITER=[190000]);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           ITER=[360000]);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1[0])\n",
    "dictionary['RO'].append(score2[0])\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/simlex999.csv\n",
      "[-0.04854133] 42\n",
      "[-0.20640195] 42\n",
      "-0.062236629053625904 42\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/simlex999.csv'\n",
    "print(Path)\n",
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           ITER=[190000]);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = corr_experiment(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           ITER=[360000]);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1[0])\n",
    "dictionary['RO'].append(score2[0])\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >Evaluation</th> \n",
       "        <th class=\"col_heading level0 col1\" >BFGD</th> \n",
       "        <th class=\"col_heading level0 col2\" >RO</th> \n",
       "        <th class=\"col_heading level0 col3\" >word2vec</th> \n",
       "        <th class=\"col_heading level0 col4\" >number of pairs</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow0_col0\" class=\"data row0 col0\" >men3000</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow0_col1\" class=\"data row0 col1\" >0.208347</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow0_col2\" class=\"data row0 col2\" >0.0563897</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow0_col3\" class=\"data row0 col3\" >-0.144422</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow0_col4\" class=\"data row0 col4\" >60</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow1_col0\" class=\"data row1 col0\" >verb143</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow1_col1\" class=\"data row1 col1\" >0.0227791</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow1_col2\" class=\"data row1 col2\" >-0.214124</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow1_col3\" class=\"data row1 col3\" >-0.113896</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow1_col4\" class=\"data row1 col4\" >11</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow2_col0\" class=\"data row2 col0\" >wordsim353</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow2_col1\" class=\"data row2 col1\" >0.252956</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow2_col2\" class=\"data row2 col2\" >-0.17102</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow2_col3\" class=\"data row2 col3\" >0.36092</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow2_col4\" class=\"data row2 col4\" >32</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow3_col0\" class=\"data row3 col0\" >MTURK-771</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow3_col1\" class=\"data row3 col1\" >0.402626</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow3_col2\" class=\"data row3 col2\" >0.324727</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow3_col3\" class=\"data row3 col3\" >0.475184</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow3_col4\" class=\"data row3 col4\" >30</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow4_col0\" class=\"data row4 col0\" >mturk287</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow4_col1\" class=\"data row4 col1\" >0.369697</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow4_col2\" class=\"data row4 col2\" >0.490909</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow4_col3\" class=\"data row4 col3\" >0.69697</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow4_col4\" class=\"data row4 col4\" >10</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row5\" >5</th> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow5_col0\" class=\"data row5 col0\" >rw2034</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow5_col1\" class=\"data row5 col1\" >1</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow5_col2\" class=\"data row5 col2\" >0.5</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow5_col3\" class=\"data row5 col3\" >0.5</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow5_col4\" class=\"data row5 col4\" >3</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row6\" >6</th> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow6_col0\" class=\"data row6 col0\" >simlex999</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow6_col1\" class=\"data row6 col1\" >-0.0485413</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow6_col2\" class=\"data row6 col2\" >-0.206402</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow6_col3\" class=\"data row6 col3\" >-0.0622366</td> \n",
       "        <td id=\"T_f8dfc4a2_8703_11e8_a8f6_484520c17fffrow6_col4\" class=\"data row6 col4\" >42</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4e07e3b828>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dictionary)\n",
    "cols = df.columns.tolist()\n",
    "j = cols.index('Evaluation')\n",
    "cols[0],cols[j]=cols[j], cols[0]\n",
    "j = cols.index('number of pairs')\n",
    "cols[-1],cols[j]=cols[j], cols[-1]\n",
    "df=df[cols]\n",
    "df.style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
