{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm, svd\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec, Word2Vec\n",
    "import logging\n",
    "\n",
    "from util.word2vec_as_MF import Word2vecMF\n",
    "from util.functions import *\n",
    "\n",
    "import time\n",
    "dimension = 20\n",
    "model =  Word2vecMF()\n",
    "dictionary = {'Evaluation':[],'BFGD':[],'RO':[], 'word2vec':[], 'number of pairs':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "model.load_matrices(from_file='enwik-200/matrices2.npz');\n",
    "sentences=load(from_file='data/x2')\n",
    "skip = Word2Vec(sentences, size=dimension, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/men3000.csv\n",
      "0.20834729057134707 60\n",
      "0.056389737792431845 60\n",
      "-0.13107555421771389 60\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/men3000.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/verb143.csv\n",
      "0.02277910237891026 11\n",
      "-0.21412356236175645 11\n",
      "-0.13211879379767952 11\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/verb143.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/wordsim353.csv\n",
      "0.25295573380916286 32\n",
      "-0.17102007220576013 32\n",
      "0.3193107886199723 32\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/wordsim353.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/MTURK-771.csv\n",
      "0.40262634747915527 30\n",
      "0.32472738583310534 30\n",
      "0.46583579064337866 30\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/MTURK-771.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=',');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/mturk287.csv\n",
      "0.3696969696969697 10\n",
      "0.49090909090909085 10\n",
      "0.7454545454545454 10\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/mturk287.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/rw2034.csv\n",
      "1.0 3\n",
      "0.5 3\n",
      "0.5 3\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/rw2034.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/simlex999.csv\n",
      "-0.04854132917073165 42\n",
      "-0.2064019455723765 42\n",
      "-0.08889789332269221 42\n"
     ]
    }
   ],
   "source": [
    "Path = 'datasets/simlex999.csv'\n",
    "print(Path)\n",
    "\n",
    "df = pd.read_csv(Path,header=None, delimiter=';');\n",
    "score1, _, _, chosen_pairs = correlation(model = model, benchmark = df, \n",
    "                                            from_folder='enwik-200/AMiter_fromPMM_D2_dim20_step1e-05_0.006',\n",
    "                                           index=190000);\n",
    "print(score1, len(chosen_pairs))\n",
    "\n",
    "score2, _, _, chosen_pairs = correlation(model = model, benchmark = df,\n",
    "                                            from_folder='enwik-200/PSiter_fromSVD_dim20_step5e-05_0.0',\n",
    "                                           index=360000);\n",
    "print(score2, len(chosen_pairs))\n",
    "\n",
    "score3, _, _, chosen_pairs = corr_word2vec(skip ,df, model_vocab=model.vocab)\n",
    "print(score3, len(chosen_pairs))\n",
    "\n",
    "dictionary['Evaluation'].append(Path.split('/')[1].split('.')[0])\n",
    "dictionary['BFGD'].append(score1)\n",
    "dictionary['RO'].append(score2)\n",
    "dictionary['word2vec'].append(score3)\n",
    "dictionary['number of pairs'].append(len(chosen_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >Evaluation</th> \n",
       "        <th class=\"col_heading level0 col1\" >BFGD</th> \n",
       "        <th class=\"col_heading level0 col2\" >RO</th> \n",
       "        <th class=\"col_heading level0 col3\" >word2vec</th> \n",
       "        <th class=\"col_heading level0 col4\" >number of pairs</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow0_col0\" class=\"data row0 col0\" >men3000</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow0_col1\" class=\"data row0 col1\" >0.208347</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow0_col2\" class=\"data row0 col2\" >0.0563897</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow0_col3\" class=\"data row0 col3\" >-0.131076</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow0_col4\" class=\"data row0 col4\" >60</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow1_col0\" class=\"data row1 col0\" >verb143</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow1_col1\" class=\"data row1 col1\" >0.0227791</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow1_col2\" class=\"data row1 col2\" >-0.214124</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow1_col3\" class=\"data row1 col3\" >-0.132119</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow1_col4\" class=\"data row1 col4\" >11</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow2_col0\" class=\"data row2 col0\" >wordsim353</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow2_col1\" class=\"data row2 col1\" >0.252956</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow2_col2\" class=\"data row2 col2\" >-0.17102</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow2_col3\" class=\"data row2 col3\" >0.319311</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow2_col4\" class=\"data row2 col4\" >32</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow3_col0\" class=\"data row3 col0\" >MTURK-771</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow3_col1\" class=\"data row3 col1\" >0.402626</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow3_col2\" class=\"data row3 col2\" >0.324727</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow3_col3\" class=\"data row3 col3\" >0.465836</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow3_col4\" class=\"data row3 col4\" >30</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow4_col0\" class=\"data row4 col0\" >mturk287</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow4_col1\" class=\"data row4 col1\" >0.369697</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow4_col2\" class=\"data row4 col2\" >0.490909</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow4_col3\" class=\"data row4 col3\" >0.745455</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow4_col4\" class=\"data row4 col4\" >10</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row5\" >5</th> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow5_col0\" class=\"data row5 col0\" >rw2034</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow5_col1\" class=\"data row5 col1\" >1</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow5_col2\" class=\"data row5 col2\" >0.5</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow5_col3\" class=\"data row5 col3\" >0.5</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow5_col4\" class=\"data row5 col4\" >3</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fff\" class=\"row_heading level0 row6\" >6</th> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow6_col0\" class=\"data row6 col0\" >simlex999</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow6_col1\" class=\"data row6 col1\" >-0.0485413</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow6_col2\" class=\"data row6 col2\" >-0.206402</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow6_col3\" class=\"data row6 col3\" >-0.0888979</td> \n",
       "        <td id=\"T_431ba4de_87f7_11e8_a8f6_484520c17fffrow6_col4\" class=\"data row6 col4\" >42</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f51cbb904e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dictionary)\n",
    "cols = df.columns.tolist()\n",
    "j = cols.index('Evaluation')\n",
    "cols[0],cols[j]=cols[j], cols[0]\n",
    "j = cols.index('number of pairs')\n",
    "cols[-1],cols[j]=cols[j], cols[-1]\n",
    "df=df[cols]\n",
    "df.style\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
